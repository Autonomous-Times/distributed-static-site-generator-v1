aqua Main

import "../../.fluence/aqua-dependencies/node_modules/@fluencelabs/aqua-lib/builtin.aqua"
import "../../.fluence/aqua-dependencies/node_modules/@fluencelabs/aqua-lib/subnet.aqua"
import "../../.fluence/aqua-dependencies/node_modules/@fluencelabs/aqua-ipfs/ipfs.aqua"

import "./services.aqua"
import "./helpers.aqua"
import "./types.aqua"
import "./dsg_helpers.aqua"

import Spell, Log from "../../.fluence/aqua-dependencies/node_modules/@fluencelabs/spell/spell_service.aqua"

export renderOnDSG, bulkUpload, bulkRender, subnet

-- temp use of remote kubo to store content -- to do adopt custom docker-compose to run with remote ipfs node 
const SUBNETKUBO = "/dns4/ipfs/tcp/5001"
const TABLELANDGATEWAY = "https://tableland.transport-union.dev"
const PINATAJWTKEY = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VySW5mb3JtYXRpb24iOnsiaWQiOiI0MzNhYjNkMS02YTZjLTQzMGUtODhkZC03Yzc0Y2MyZmQzMDkiLCJlbWFpbCI6ImpvZXJhQGpvZXJhbXVsZGVycy5jb20iLCJlbWFpbF92ZXJpZmllZCI6dHJ1ZSwicGluX3BvbGljeSI6eyJyZWdpb25zIjpbeyJpZCI6Ik5ZQzEiLCJkZXNpcmVkUmVwbGljYXRpb25Db3VudCI6MX1dLCJ2ZXJzaW9uIjoxfSwibWZhX2VuYWJsZWQiOmZhbHNlLCJzdGF0dXMiOiJBQ1RJVkUifSwiYXV0aGVudGljYXRpb25UeXBlIjoic2NvcGVkS2V5Iiwic2NvcGVkS2V5S2V5IjoiNGZhNDRkZmU0NGIyMDcyMmZlYjciLCJzY29wZWRLZXlTZWNyZXQiOiI4MTc0YTJjOTc5OGQ2MjU4MzA0NTQ2NzgyZDAxMTUyNDJkNjlhODlhNDI2MWRkNWQ5N2M5NzRiOGZiNWMzYWVlIiwiaWF0IjoxNzEzMzQ1ODE0fQ.88EHF4U77_mU_RyJXMNYIhDaJ0m6AkXqRCw6rflmDow"

func subnet() -> bool: 

    -- wrkrs = getContentWorkers()
    -- Console.print(wrkrs)
    <- true

func renderOnDSG(tempTask: TuDsgPublishTaskTemp, archive_cid: string) -> string, *AquaMarineResult:

    Console.print("Starting")

    results: *AquaMarineResult
    debug: *AquaMarineResult
    queue: *[]TuDsgRenderObject
    cids: *string
    job_archive_hashes: *string

    -- get encrypted publicationData from chain .... 

    logNumber = (n: u32):
        Console.print(n)
    logString = (s: string):
        Console.print(s)
    logCI = (ci: TuContentItem):
        Console.print(ci)
    logQueue = (q: *[]TuDsgRenderObject):
        Console.print(q)
    logTemplateData = (td: AquaMarineResult):
        Console.print(td)

    task = fromTempTask(tempTask, SUBNETKUBO)
    Console.print(task)

    cw = randomContentWorker()
    on cw.worker_id! via cw.host_id:    
        logString("0")
        mapping = CioKubo.get(SUBNETKUBO, task.author.content_mappings)
        logString("1")
        mapped = TuDsgContent.map(task, mapping)
        logString("2")
        amr = CioPinata.addAsFile(mapped.body, mapped.item.slug, PINATAJWTKEY)  
        logString("3") 
        contentItem = TuDsgContent.includeCid(mapped.item, amr.result)
        logCI(contentItem)
        results <- TuContentStore.insert(contentItem, task.publication.table, TABLELANDGATEWAY)
        logString("3b") 
        main = TuDsgContent.pebble(task, contentItem)
        queue <<- main
        for ripple <- main!.template.ripples:
            items = TuContentStore.queryRipple(ripple, task.publication.table, TABLELANDGATEWAY) 
            for item <- items: 
                queue <- TuDsgContent.ripple(task, ripple, item)
            
    logQueue(queue)

    downloads: *string
    for rw <- getRenderWorkers() par:
        on rw.worker_id! via rw.host_id:
            downloads <- CioKubo.getRecursive(SUBNETKUBO, archive_cid, task.publication.name)
            logString("4")   
            downloads <- CioKubo.getRecursive(SUBNETKUBO, task.publication.templates, "templates")
            logString("5")
    join downloads[5]

    finished: *bool
    for rw <- getRenderWorkers() par:
        on rw.worker_id! via rw.host_id: 
            for ros <- queue:
                for ro <- ros: 
                    body = CioKubo.get(SUBNETKUBO, ro.body_cid)
                    collections: *[]TuContentItem
                    -- for c <- ro.template.collections:
                    --     if c.source == "tableland":
                    --         collections <- TuContentStore.queryCollection(c, task.publication.table) 
                    templateDataResult = TuDsgRenderer.map(ro, body, collections, task.publication)
                    results <- TuDsgRenderer.single(ro, templateDataResult.output!)
                    logString("8")
            finished <<- true
    join finished[2]
    logString("9")

    hashes: *AMResponse
    for rw <- getRenderWorkers() par:
        on rw.worker_id! via rw.host_id: 
            -- fds_ <- CioVault.inspect("unamore")
            -- for f <- fds_:
            --     logString(f)   
            hashes <- CioKubo.hash(SUBNETKUBO,task.publication.name)
    join hashes[2]
    logString("10")

    leader = selectLeader(hashes) 
    logString("11")
    on leader.worker_id! via leader.host_id:
        logString("12")
        pinataResult = CioPinata.addFolder(task.publication.name, PINATAJWTKEY) 
        cids <<- pinataResult.result
        logString(cids!)

    hw = randomWebHostWorker()
    on hw.worker_id! via hw.host_id:  
        s <- TuDsgWebHost.update(task.publication, cids!)
        logString(s.result)
        
    -- make tx to update publication 
                             
    <- cids!, results

func bulkUpload(tasks: []TuDsgPublishTaskTemp) -> bool:

    -- logString = (s: string):
    --     Console.print(s)
    -- logCI = (ci: TuContentItem):
    --     Console.print(ci)

    -- results: *AquaMarineResult
    -- cw = randomContentWorker()
    -- for tempTask <- tasks:
    --     task = fromTempTask(tempTask, SUBNETKUBO) 
    --     on cw.worker_id! via cw.host_id:   
    --         mapping = CioKubo.get(SUBNETKUBO, task.author.content_mappings)
    --         mapped = TuDsgContent.map(task, mapping) 
    --         cid = CioKubo.add(SUBNETKUBO, mapped.body)
    --         contentItem = TuDsgContent.includeCid(mapped.item, cid)
    --         -- logCI(contentItem)
    --         results <- TuContentStore.insert(contentItem, task.publication.table, TABLELANDGATEWAY)
    --         logString(results!.results!)

    <- true

func bulkRender(publication_cid: string, post_type: string, archive_cid: string) -> *AquaMarineResult:

    results: *AquaMarineResult

    -- publication = fetchPublication(publication_cid, SUBNETKUBO)

    -- Console.print(publication)

    -- w = randomDevWorker()
    -- on w.workerId via w.hostId:
    --     queue: *[]TuDsgRenderObject
    --     kubo = Ipfs.get_local_api_multiaddr()
    --     if kubo.success == true:
    --         queue <- TuDsgContent.bulk(publication, post_type, kubo.multiaddr)
    --         debug <- TuDsgRenderer.imports(archive_cid, publication, kubo.multiaddr)
    --         for ros <- queue:
    --             for ro <- ros:
    --                 results <- TuDsgRenderer.single(ro, kubo.multiaddr)
    --                 Peer.timeout(10,"buffering not to overload tableland")
    --         results <- TuDsgRenderer.collect(publication.name, kubo.multiaddr)


    <- results